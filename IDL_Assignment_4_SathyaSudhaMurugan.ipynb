{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IDL_Assignment_4_SathyaSudhaMurugan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SathyaSudha-96/Deep-Learning-2021-22/blob/main/IDL_Assignment_4_SathyaSudhaMurugan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7xSJUs09WAG"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import tensorboard\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7iso67R_vJl"
      },
      "source": [
        "cifar_data = tf.keras.datasets.cifar10\n",
        "(train_images, train_labels),(test_images,test_labels) = cifar_data.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lXub8MaKp2e"
      },
      "source": [
        "print('Shape of Training Images',train_images.shape)\n",
        "print('Shape of Training Labels',train_labels.shape)\n",
        "print('Shape of Testing Images',test_images.shape)\n",
        "print('Shape of Testing Labels',test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L-c7FbfLyMX"
      },
      "source": [
        "figure, ax = plt.subplots(2,4)\n",
        "figure.suptitle(\"CIFAR_10 Data Samples\")\n",
        "ax[0,0].imshow(train_images[1])\n",
        "ax[0,1].imshow(train_images[800])\n",
        "ax[0,2].imshow(train_images[30])\n",
        "ax[0,3].imshow(train_images[40])\n",
        "ax[1,0].imshow(train_images[5])\n",
        "ax[1,1].imshow(train_images[100])\n",
        "ax[1,2].imshow(train_images[7])\n",
        "ax[1,3].imshow(train_images[20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hXZwk71MhlW"
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.astype(np.float32) / 255, train_labels.reshape(-1).astype(np.int32)))\n",
        "train_data = train_data.shuffle(buffer_size=50000).batch(128)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.astype(np.float32) / 255, test_labels.reshape(-1).astype(np.int32))).batch(128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHPZVeX5P7iQ"
      },
      "source": [
        "Each convolution is preceded by batch normalization and relu activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHDhAG2ZjzJT"
      },
      "source": [
        "def bn_relu_conv(tensor,filters, kernel_size):\n",
        "    x = layers.BatchNormalization()(tensor)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(filters, kernel_size, strides =1, padding=\"same\")(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4krDcx6pA8x"
      },
      "source": [
        "  def dense_block(tensor,filter, r):\n",
        "    for _ in range(r):\n",
        "      x = bn_relu_conv(tensor, filters=4*filter, kernel_size=1) #for 1*1 convolution, the number for filters if 4*filters\n",
        "      x = bn_relu_conv(tensor=x, filters=filter, kernel_size=3)\n",
        "      tensor = layers.Concatenate()([tensor, x])\n",
        "    return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ley0LqcQQFw"
      },
      "source": [
        "Transition Layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NunqCwf_pHqM"
      },
      "source": [
        " def transition_block(x):\n",
        "    f = int(tf.keras.backend.int_shape(x)[-1] // 2)\n",
        "    x = bn_relu_conv(tensor=x, filters=f, kernel_size=1)\n",
        "    x = layers.AvgPool2D(2, strides=2, padding='same')(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2h7fKpUvJTP"
      },
      "source": [
        "def densenet_121():\n",
        "  repetitions = 6, 12, 24, 16\n",
        "  filter = 32\n",
        "  inputs = tf.keras.layers.Input((32, 32, 3))\n",
        "  x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
        "  x = layers.MaxPool2D(3, strides=2, padding='same')(x)\n",
        "  for r in repetitions:\n",
        "    d = dense_block(x, filter, r)\n",
        "    x = transition_block(d)\n",
        "  x = layers.GlobalAvgPool2D()(d)\n",
        "  output = layers.Dense(1000, activation='softmax')(x)\n",
        "  model = keras.models.Model(inputs, output, name = \"DenseNet_121\")\n",
        "  return model\n",
        "densenet_121_model = densenet_121()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WvKJldcoESH"
      },
      "source": [
        "def densenet_169():\n",
        "  repetitions = 6, 12, 32, 32\n",
        "  filter = 32\n",
        "  inputs = tf.keras.layers.Input((32, 32, 3))\n",
        "  x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
        "  x = layers.MaxPool2D(3, strides=2, padding='same')(x)\n",
        "  for r in repetitions:\n",
        "    d = dense_block(x, filter, r)\n",
        "    x = transition_block(d)\n",
        "  x = layers.GlobalAvgPool2D()(d)\n",
        "  output = layers.Dense(1000, activation='softmax')(x)\n",
        "  model = keras.models.Model(inputs, output, name = \"DenseNet_121\")\n",
        "  return model\n",
        "densenet_169_model = densenet_169()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L52-KKOLoMug"
      },
      "source": [
        "def densenet_201():\n",
        "  repetitions = 6, 12, 48, 32\n",
        "  filter = 32\n",
        "  inputs = tf.keras.layers.Input((32, 32, 3))\n",
        "  x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
        "  x = layers.MaxPool2D(3, strides=2, padding='same')(x)\n",
        "  for r in repetitions:\n",
        "    d = dense_block(x, filter, r)\n",
        "    x = transition_block(d)\n",
        "  x = layers.GlobalAvgPool2D()(d)\n",
        "  output = layers.Dense(1000, activation='softmax')(x)\n",
        "  model = keras.models.Model(inputs, output, name = \"DenseNet_121\")\n",
        "  return model\n",
        "densenet_201_model = densenet_201()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4X8z7O5ELzT"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels, model,optimizer):\n",
        "  #logits is false as we have used softmax in output\n",
        "  loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(images)\n",
        "    loss = loss_fn(labels, logits)\n",
        "  #Calculate gradients using gradient tape\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  #Assign new variables to the model using optimizer instead of sub assign\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss, logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCTOWyQxJN4n"
      },
      "source": [
        "# Set up logging.\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = 'logs/func/%s' % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzk_kdhGNhXk"
      },
      "source": [
        "def training_loop(epochs, model,optimizer):\n",
        "  train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "  start_time = time.time()\n",
        "  for epoch in range(epochs):\n",
        "    print(\"Starting epoch\", epoch+1)\n",
        "    for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "      loss, logits = train_step(image_batch, label_batch,model,optimizer)\n",
        "      #Calculate  traning accuracy\n",
        "      train_acc_metric(label_batch, logits)\n",
        "    \n",
        "      if not step % 100:  \n",
        "        print(\"Loss: {} Training Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPnW9GO_NqTU"
      },
      "source": [
        "training_loop(10, densenet_121_model, optimizer = tf.optimizers.Adam())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP90g-4XmXlu"
      },
      "source": [
        "Without @tf.function, it took 1824.09 seconds (31.4 minutes)\n",
        "\n",
        "With @tf.function, it took only 706.28 seconds (11.77 minutes) which is less than half of without @tf.function.âš¡"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xilqdbut3m5J"
      },
      "source": [
        "test_acc_metric = tf.metrics.SparseCategoricalAccuracy()\n",
        "for img_batch, lbl_batch in test_data:\n",
        "    test_acc_metric(lbl_batch, densenet_121_model(img_batch))\n",
        "\n",
        "test_acc_metric.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4QTgifDulMZ"
      },
      "source": [
        "training_loop(50, densenet_169_model, optimizer = tf.optimizers.Adam())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjLu_VZW5MJb"
      },
      "source": [
        "test_acc_metric = tf.metrics.SparseCategoricalAccuracy()\n",
        "for img_batch, lbl_batch in test_data:\n",
        "    test_acc_metric(lbl_batch, densenet_169_model(img_batch))\n",
        "\n",
        "test_acc_metric.result()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txLwAXHyPuaI"
      },
      "source": [
        "TensorBoard to view the computational graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQv6lrZbvV2U"
      },
      "source": [
        "def training_loop_TensorBoard(epochs, model,optimizer):\n",
        "  train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "  start_time = time.time()\n",
        "  for epoch in range(epochs):\n",
        "    print(\"Starting epoch\", epoch+1)\n",
        "    for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "      #Enabling the tracing\n",
        "      tf.summary.trace_on(graph=True, profiler=True)\n",
        "      loss, logits = train_step(image_batch, label_batch,model,optimizer)\n",
        "      #Calculate  traning accuracy\n",
        "      train_acc_metric(label_batch, logits)\n",
        "      with writer.as_default():\n",
        "        #Exporting the trace \n",
        "        tf.summary.trace_export(\n",
        "        name=\"my_func_trace\",\n",
        "        step=0,\n",
        "        profiler_outdir=logdir)\n",
        "    \n",
        "      if not step % 100:  \n",
        "        print(\"Loss: {} Training Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
        "training_loop_TensorBoard(1, densenet_201_model, optimizer = tf.optimizers.Adam())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cw5Z8Di8wIh"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/func"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfAKczvePlH1"
      },
      "source": [
        "Training pipeline with high level keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty8m99gXoaPJ"
      },
      "source": [
        "def densenet_264():\n",
        "  repetitions = 6, 12, 64, 48\n",
        "  filter = 32\n",
        "  inputs = tf.keras.layers.Input((32, 32, 3))\n",
        "  x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)\n",
        "  x = layers.MaxPool2D(3, strides=2, padding='same')(x)\n",
        "  for r in repetitions:\n",
        "    d = dense_block(x, filter, r)\n",
        "    x = transition_block(d)\n",
        "  x = layers.GlobalAvgPool2D()(d)\n",
        "  output = layers.Dense(1000, activation='softmax')(x)\n",
        "  model = keras.models.Model(inputs, output, name = \"DenseNet_121\")\n",
        "  return model\n",
        "densenet_264_model = densenet_264()  \n",
        "#densenet_264_model.summary()\n",
        "\n",
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "accuracy_metric = tf.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "densenet_264_model.compile(optimizer=optimizer, loss=loss_fn, metrics=[accuracy_metric])\n",
        "\n",
        "densenet_264_model.fit(train_data, steps_per_epoch=1000, epochs=2, validation_data=test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}